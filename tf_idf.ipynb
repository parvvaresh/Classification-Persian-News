{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "\n",
    "TF-IDF is a statistical measure used to evaluate the importance of a word in a document relative to a collection or corpus of documents. It is widely used in information retrieval and text mining, particularly in tasks like document classification and keyword extraction.\n",
    "\n",
    "## TF-IDF Formula\n",
    "\n",
    "The TF-IDF score is computed as the product of two components:\n",
    "\n",
    "### 1. **TF (Term Frequency)**:\n",
    "This measures how frequently a word appears in a document. The idea is that words that appear more frequently in a document are likely more important.\n",
    "\n",
    "\\[\n",
    "\\text{TF}(t, d) = \\frac{\\text{Count of term t in document d}}{\\text{Total number of terms in document d}}\n",
    "\\]\n",
    "\n",
    "- **t**: The term (word) in the document.\n",
    "- **d**: The specific document.\n",
    "- The numerator is the number of times the term **t** appears in document **d**.\n",
    "- The denominator is the total number of words in document **d**.\n",
    "\n",
    "#### Example:\n",
    "If the word \"apple\" appears 3 times in a document that contains 100 words, then the **TF** of \"apple\" in that document is:\n",
    "\n",
    "\\[\n",
    "\\text{TF}(\\text{apple}, d) = \\frac{3}{100} = 0.03\n",
    "\\]\n",
    "\n",
    "### 2. **IDF (Inverse Document Frequency)**:\n",
    "This measures how important a word is across all documents in the corpus. The idea is that words that appear in many documents are less informative (common words like \"the\", \"is\", etc.), while words that appear in fewer documents are more informative (unique to a specific document or topic).\n",
    "\n",
    "\\[\n",
    "\\text{IDF}(t) = \\log \\left( \\frac{\\text{Total number of documents}}{\\text{Number of documents containing term t}} \\right)\n",
    "\\]\n",
    "\n",
    "- **Total number of documents**: The total number of documents in the corpus.\n",
    "- **Number of documents containing term t**: The number of documents where the term **t** appears.\n",
    "\n",
    "#### Example:\n",
    "If there are 100 documents in the corpus, and the term \"apple\" appears in 10 of those documents, the **IDF** for \"apple\" is:\n",
    "\n",
    "\\[\n",
    "\\text{IDF}(\\text{apple}) = \\log \\left( \\frac{100}{10} \\right) = \\log(10) = 1\n",
    "\\]\n",
    "\n",
    "## TF-IDF Calculation:\n",
    "\n",
    "Once we have **TF** and **IDF**, we multiply them together to get the **TF-IDF** score for a term in a document.\n",
    "\n",
    "\\[\n",
    "\\text{TF-IDF}(t, d) = \\text{TF}(t, d) \\times \\text{IDF}(t)\n",
    "\\]\n",
    "\n",
    "#### Example:\n",
    "If the term \"apple\" has a **TF** of 0.03 in a document and an **IDF** of 1, the **TF-IDF** for \"apple\" in that document would be:\n",
    "\n",
    "\\[\\text{TF-IDF}(\\text{apple}, d) = 0.03 \\times 1 = 0.03\\]\n",
    "\n",
    "## Key Insights:\n",
    "- **TF** captures the frequency of a term in a document.\n",
    "- **IDF** adjusts the importance of the term based on its overall frequency in the corpus, emphasizing rare terms.\n",
    "- **TF-IDF** combines these two, giving more weight to terms that are frequent in a document but rare across the entire corpus.\n",
    "\n",
    "## Why Use TF-IDF?\n",
    "\n",
    "- **TF** by itself can be misleading because common words (like \"the\" or \"and\") will have high frequencies in many documents.\n",
    "- **IDF** helps to reduce the weight of terms that appear in many documents, making rare terms more significant.\n",
    "- **TF-IDF** helps identify terms that are both significant in a document and relatively rare across the corpus, which is useful in many text analysis tasks like search engines, document clustering, and keyword extraction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "class TfIdf:\n",
    "    def __init__(self, ducs: list) -> None:\n",
    "        self.ducs = ducs\n",
    "        self.size_ducs = len(ducs)\n",
    "        self.words = self._collect_words()\n",
    "        self.word_index = {word: idx for idx, word in enumerate(self.words)}\n",
    "        self.word_count = self._compute_word_count()\n",
    "        self.idf_values = self._compute_idf()\n",
    "\n",
    "    def transform(self) -> np.array:\n",
    "        return self.tf_idf()\n",
    "\n",
    "    def tf_idf(self) -> np.array:\n",
    "        vectors = np.zeros((self.size_ducs, len(self.words)))\n",
    "        for i, duc in enumerate(self.ducs):\n",
    "            vectors[i] = self._tf_idf(duc)\n",
    "        return vectors\n",
    "\n",
    "    def _tf_idf(self, duc: list) -> np.array:\n",
    "        vector = np.zeros(len(self.words))\n",
    "        tf = Counter(duc)\n",
    "        for word in tf:\n",
    "            if word in self.word_index:\n",
    "                vector[self.word_index[word]] = (tf[word] / len(duc)) * self.idf_values[word]\n",
    "        return vector\n",
    "\n",
    "    def _compute_idf(self) -> dict:\n",
    "        idf_values = {}\n",
    "        for word in self.word_index:\n",
    "            df = self.word_count[word]\n",
    "            idf_values[word] = np.log(self.size_ducs / (df + 1))  # Added +1 for smoothing\n",
    "        return idf_values\n",
    "\n",
    "    def _collect_words(self) -> list:\n",
    "        words = set()\n",
    "        for duc in self.ducs:\n",
    "            words.update(duc)\n",
    "        return sorted(words)\n",
    "\n",
    "    def _compute_word_count(self) -> dict:\n",
    "        word_count = defaultdict(int)\n",
    "        for duc in self.ducs:\n",
    "            unique_words = set(duc)\n",
    "            for word in unique_words:\n",
    "                word_count[word] += 1\n",
    "        return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['apple', 'banana', 'computer', 'data', 'football', 'fruit', 'game', 'green', 'learning', 'orange', 'players', 'programming', 'python', 'science', 'soccer', 'sports', 'sweet', 'tasty', 'team']\n",
      "TF-IDF Matrix:\n",
      " [[0.04794701 0.04794701 0.         0.         0.         0.09589402\n",
      "  0.         0.11552453 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.04794701 0.\n",
      "  0.        ]\n",
      " [0.         0.         0.11552453 0.11552453 0.         0.\n",
      "  0.         0.         0.11552453 0.         0.         0.11552453\n",
      "  0.11552453 0.11552453 0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.11552453 0.\n",
      "  0.11552453 0.         0.         0.         0.11552453 0.\n",
      "  0.         0.         0.11552453 0.11552453 0.         0.\n",
      "  0.11552453]\n",
      " [0.04794701 0.04794701 0.         0.         0.         0.04794701\n",
      "  0.         0.         0.         0.11552453 0.         0.\n",
      "  0.         0.         0.         0.         0.04794701 0.11552453\n",
      "  0.        ]]\n",
      "\n",
      "TF-IDF Vector for Document 0: [0.04794701 0.04794701 0.         0.         0.         0.09589402\n",
      " 0.         0.11552453 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.04794701 0.\n",
      " 0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Sample documents (ducs)\n",
    "ducs = [\n",
    "    [\"apple\", \"banana\", \"fruit\", \"green\", \"fruit\", \"sweet\"],\n",
    "    [\"computer\", \"programming\", \"python\", \"data\", \"science\", \"learning\"],\n",
    "    [\"football\", \"soccer\", \"sports\", \"game\", \"team\", \"players\"],\n",
    "    [\"apple\", \"orange\", \"banana\", \"fruit\", \"sweet\", \"tasty\"]\n",
    "]\n",
    "\n",
    "# Initialize the TfIdf transformer\n",
    "tfidf = TfIdf(ducs)\n",
    "\n",
    "# Transform the documents into TF-IDF vectors\n",
    "tfidf_matrix = tfidf.transform()\n",
    "\n",
    "# Display the vocabulary (terms) and the corresponding TF-IDF matrix\n",
    "print(\"Vocabulary:\", tfidf.words)\n",
    "print(\"TF-IDF Matrix:\\n\", tfidf_matrix)\n",
    "\n",
    "# Example: Get TF-IDF vector for the first document (document at index 0)\n",
    "print(\"\\nTF-IDF Vector for Document 0:\", tfidf_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
