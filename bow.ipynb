{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Bag of Words (BoW)** algorithm is a natural language processing (NLP) technique used to represent text data in numerical form. It is a simple and commonly used method for feature extraction from text. Here's a step-by-step explanation of the algorithm:\n",
    "\n",
    "---\n",
    "\n",
    "### **Algorithm Steps**\n",
    "\n",
    "1. **Corpus Creation**:\n",
    "   - Collect all the text documents (the corpus) that you want to process.\n",
    "\n",
    "2. **Text Preprocessing**:\n",
    "   - Standardize the text data by:\n",
    "     - Converting all text to lowercase to maintain uniformity.\n",
    "     - Removing punctuation, special characters, and numbers (if not needed).\n",
    "     - Tokenizing the text (splitting it into individual words).\n",
    "     - Removing stopwords (e.g., \"and,\" \"the,\" \"is\") that do not carry significant meaning.\n",
    "     - (Optional) Applying stemming or lemmatization to reduce words to their root forms.\n",
    "\n",
    "3. **Vocabulary Construction**:\n",
    "   - Create a unique list of all words (vocabulary) in the corpus. Each word in this vocabulary will be treated as a feature.\n",
    "\n",
    "4. **Vectorization**:\n",
    "   - For each document in the corpus, create a vector of length equal to the size of the vocabulary.\n",
    "   - Fill the vector with word counts or occurrences. The position of each word in the vector corresponds to its position in the vocabulary.\n",
    "\n",
    "5. **Matrix Representation**:\n",
    "   - Combine all vectors into a matrix where:\n",
    "     - Each row represents a document.\n",
    "     - Each column represents a word in the vocabulary.\n",
    "     - Each cell contains the count (or frequency) of the word in the corresponding document.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example**\n",
    "\n",
    "#### Corpus:\n",
    "- Document 1: \"The cat sat on the mat.\"\n",
    "- Document 2: \"The dog barked at the cat.\"\n",
    "\n",
    "#### 1. **Preprocessing**:\n",
    "- Document 1: [\"cat\", \"sat\", \"mat\"]\n",
    "- Document 2: [\"dog\", \"barked\", \"cat\"]\n",
    "\n",
    "#### 2. **Vocabulary**:\n",
    "- Vocabulary: [\"cat\", \"sat\", \"mat\", \"dog\", \"barked\"]\n",
    "\n",
    "#### 3. **Vectorization**:\n",
    "- Document 1: [1, 1, 1, 0, 0]  (cat: 1, sat: 1, mat: 1, dog: 0, barked: 0)\n",
    "- Document 2: [1, 0, 0, 1, 1]  (cat: 1, sat: 0, mat: 0, dog: 1, barked: 1)\n",
    "\n",
    "#### 4. **Matrix Representation**:\n",
    "|           | cat | sat | mat | dog | barked |\n",
    "|-----------|-----|-----|-----|-----|--------|\n",
    "| Document 1|  1  |  1  |  1  |  0  |   0    |\n",
    "| Document 2|  1  |  0  |  0  |  1  |   1    |\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Properties**\n",
    "- **Sparse Representation**: The matrix often has many zero values because not all words appear in every document.\n",
    "- **Order-Insensitive**: The BoW representation does not consider the order of words in the document.\n",
    "- **Dimensionality**: The size of the matrix increases with the size of the vocabulary.\n",
    "\n",
    "---\n",
    "\n",
    "### **Limitations**\n",
    "1. **Context Ignorance**: BoW ignores the order and meaning of words.\n",
    "2. **High Dimensionality**: Large corpora create very large matrices.\n",
    "3. **No Semantic Understanding**: Similar words (e.g., \"run\" and \"jog\") are treated as completely different features.\n",
    "\n",
    "---\n",
    "\n",
    "### **Applications**\n",
    "- Text classification (e.g., spam detection).\n",
    "- Sentiment analysis.\n",
    "- Document similarity calculations.\n",
    "\n",
    "---\n",
    "\n",
    "By transforming text into a fixed-size numerical representation, BoW enables text data to be used in machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class BOW:\n",
    "    def __init__(self, tokenized_corpus):\n",
    "\n",
    "        self.tokenized_corpus = tokenized_corpus\n",
    "        self.vocab = None\n",
    "        self.bow = None\n",
    "\n",
    "    def build_vocabulary(self):\n",
    "\n",
    "        self.vocab = sorted(set(word for tokens in self.tokenized_corpus for word in tokens))\n",
    "\n",
    "    def vectorize_document(self, tokens):\n",
    "\n",
    "        token_counts = Counter(tokens)\n",
    "        vector = [token_counts.get(word, 0) for word in self.vocab]\n",
    "        return vector\n",
    "\n",
    "    def fit(self):\n",
    "\n",
    "        self.build_vocabulary()\n",
    "\n",
    "    def transform(self):\n",
    "\n",
    "        if self.vocab is None:\n",
    "            raise ValueError(\"Vocabulary has not been built. Please call fit() before transform().\")\n",
    "        \n",
    "        self.bow = [self.vectorize_document(tokens) for tokens in self.tokenized_corpus]\n",
    "        return self.bow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['at', 'barked', 'cat', 'dog', 'mat', 'on', 'sat', 'the']\n",
      "\n",
      "Bag of Words Matrix:\n",
      "Document 1: [0, 0, 1, 0, 1, 1, 1, 2]\n",
      "Document 2: [1, 1, 1, 1, 0, 0, 0, 2]\n"
     ]
    }
   ],
   "source": [
    "# Example input: Tokenized documents\n",
    "tokenized_corpus = [\n",
    "    [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"],\n",
    "    [\"the\", \"dog\", \"barked\", \"at\", \"the\", \"cat\"]\n",
    "]\n",
    "\n",
    "# Initialize the BOW class\n",
    "bow = BOW(tokenized_corpus)\n",
    "\n",
    "# Fit the model to build the vocabulary\n",
    "bow.fit()\n",
    "print(\"Vocabulary:\", bow.vocab)\n",
    "\n",
    "# Transform the corpus into a BoW matrix\n",
    "bow_matrix = bow.transform()\n",
    "\n",
    "# Display the Bag of Words matrix\n",
    "print(\"\\nBag of Words Matrix:\")\n",
    "for i, vector in enumerate(bow_matrix):\n",
    "    print(f\"Document {i+1}: {vector}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['at' 'barked' 'cat' 'dog' 'mat' 'on' 'sat' 'the']\n",
      "\n",
      "Bag of Words Matrix (as dense array):\n",
      "[[0 0 1 0 1 1 1 2]\n",
      " [1 1 1 1 0 0 0 2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = [\n",
    "    \"The cat sat on the mat.\",\n",
    "    \"The dog barked at the cat.\"\n",
    "]\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "bow_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(\"Vocabulary:\", vocabulary)\n",
    "\n",
    "# Display the Bag of Words matrix\n",
    "print(\"\\nBag of Words Matrix (as dense array):\")\n",
    "print(bow_matrix.toarray())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
